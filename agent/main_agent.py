import os
import asyncio
from typing import Dict, Any, List, Optional
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import httpx
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv
import logging

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI app
app = FastAPI(title="EduBot Main Agent", version="1.0.0")

# Initialize LLM
llm = ChatOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
    temperature=0.7
)

# Backend API URL
BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8000/api/v1")

class ProcessRequest(BaseModel):
    message: str
    chat_history: List[Dict[str, Any]] = []
    user_id: str = None

class ProcessResponse(BaseModel):
    reply: str
    metadata: Dict[str, Any] = {}

class LectureGenerationRequest(BaseModel):
    title: str
    subject: str
    grade: str = None
    requirements: str
    user_preferences: Dict[str, Any] = {}

class SlideGenerationRequest(BaseModel):
    title: str
    subject: str
    presentation_type: str = None
    duration: int = None
    requirements: str
    user_preferences: Dict[str, Any] = {}

class SlideFromLectureRequest(BaseModel):
    lecture_content: str
    lecture_title: str
    lecture_subject: str
    include_intro: bool = True
    include_conclusion: bool = True
    include_questions: bool = False
    slide_style: str = "professional"

# Agent State
class AgentState(BaseModel):
    message: str
    chat_history: List[Dict[str, Any]] = []
    user_id: Optional[str] = None
    intent: Optional[str] = None
    entities: Dict[str, Any] = {}
    response: Optional[str] = None
    tools_used: List[str] = []
    metadata: Dict[str, Any] = {}

class EduBotAgent:
    def __init__(self):
        self.backend_url = BACKEND_URL
        self.llm = llm
        self.graph = self._create_graph()
    
    def _create_graph(self):
        """T·∫°o LangGraph workflow"""
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("understand_intent", self.understand_intent)
        workflow.add_node("route_request", self.route_request)
        workflow.add_node("handle_chat", self.handle_chat)
        workflow.add_node("handle_lecture_creation", self.handle_lecture_creation)
        workflow.add_node("handle_slide_creation", self.handle_slide_creation)
        workflow.add_node("handle_search", self.handle_search)
        workflow.add_node("generate_response", self.generate_response)
        
        # Set entry point
        workflow.set_entry_point("understand_intent")
        
        # Add edges
        workflow.add_edge("understand_intent", "route_request")
        workflow.add_conditional_edges(
            "route_request",
            self.route_decision,
            {
                "chat": "handle_chat",
                "create_lecture": "handle_lecture_creation",
                "create_slide": "handle_slide_creation",
                "search": "handle_search"
            }
        )
        workflow.add_edge("handle_chat", "generate_response")
        workflow.add_edge("handle_lecture_creation", "generate_response")
        workflow.add_edge("handle_slide_creation", "generate_response")
        workflow.add_edge("handle_search", "generate_response")
        workflow.add_edge("generate_response", END)
        
        return workflow.compile(checkpointer=MemorySaver())
    
    async def understand_intent(self, state: AgentState) -> AgentState:
        """Ph√¢n t√≠ch √Ω ƒë·ªãnh c·ªßa user"""
        try:
            system_prompt = """
            B·∫°n l√† tr·ª£ l√Ω AI chuy√™n h·ªó tr·ª£ gi√°o vi√™n so·∫°n gi·∫£ng. H√£y ph√¢n t√≠ch tin nh·∫Øn c·ªßa user v√† x√°c ƒë·ªãnh √Ω ƒë·ªãnh.
            
            C√°c √Ω ƒë·ªãnh c√≥ th·ªÉ:
            - "create_lecture": Mu·ªën t·∫°o b√†i gi·∫£ng m·ªõi
            - "create_slide": Mu·ªën t·∫°o slide thuy·∫øt tr√¨nh
            - "search": Mu·ªën t√¨m ki·∫øm b√†i gi·∫£ng/slide c√≥ s·∫µn
            - "chat": Tr√≤ chuy·ªán th√¥ng th∆∞·ªùng, h·ªèi ƒë√°p
            
            Tr·∫£ v·ªÅ JSON v·ªõi format:
            {
                "intent": "intent_name",
                "entities": {
                    "subject": "m√¥n h·ªçc n·∫øu c√≥",
                    "topic": "ch·ªß ƒë·ªÅ n·∫øu c√≥",
                    "grade": "c·∫•p ƒë·ªô n·∫øu c√≥"
                }
            }
            """
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Tin nh·∫Øn user: {state.message}")
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Parse response (simplified - in real app would use structured output)
            import json
            try:
                result = json.loads(response.content)
                state.intent = result.get("intent", "chat")
                state.entities = result.get("entities", {})
            except:
                state.intent = "chat"
                state.entities = {}
            
            logger.info(f"Intent detected: {state.intent}")
            return state
            
        except Exception as e:
            logger.error(f"Error in understand_intent: {e}")
            state.intent = "chat"
            return state
    
    def route_decision(self, state: AgentState) -> str:
        """Quy·∫øt ƒë·ªãnh route d·ª±a tr√™n intent"""
        return state.intent
    
    async def route_request(self, state: AgentState) -> AgentState:
        """Route request to appropriate handler"""
        return state
    
    async def handle_chat(self, state: AgentState) -> AgentState:
        """X·ª≠ l√Ω chat th√¥ng th∆∞·ªùng"""
        try:
            # T·∫°o context t·ª´ chat history
            context = ""
            if state.chat_history:
                recent_messages = state.chat_history[-5:]  # 5 tin nh·∫Øn g·∫ßn nh·∫•t
                for msg in recent_messages:
                    context += f"{msg['sender']}: {msg['content']}\n"
            
            system_prompt = f"""
            B·∫°n l√† tr·ª£ l√Ω AI chuy√™n h·ªó tr·ª£ gi√°o vi√™n so·∫°n gi·∫£ng. B·∫°n c√≥ th·ªÉ:
            
            1. T∆∞ v·∫•n v·ªÅ ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y
            2. G·ª£i √Ω n·ªôi dung b√†i gi·∫£ng
            3. H∆∞·ªõng d·∫´n t·∫°o slide thuy·∫øt tr√¨nh
            4. Gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ gi√°o d·ª•c
            
            Context cu·ªôc tr√≤ chuy·ªán:
            {context}
            
            H√£y tr·∫£ l·ªùi m·ªôt c√°ch h·ªØu √≠ch, th√¢n thi·ªán v√† chuy√™n nghi·ªáp.
            """
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=state.message)
            ]
            
            response = await self.llm.ainvoke(messages)
            state.response = response.content
            state.tools_used.append("chat_completion")
            
            return state
            
        except Exception as e:
            logger.error(f"Error in handle_chat: {e}")
            state.response = "Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë khi x·ª≠ l√Ω tin nh·∫Øn. Vui l√≤ng th·ª≠ l·∫°i."
            return state
    
    async def handle_lecture_creation(self, state: AgentState) -> AgentState:
        """X·ª≠ l√Ω t·∫°o b√†i gi·∫£ng"""
        try:
            # Create detailed lecture outline
            system_prompt = """
            B·∫°n l√† chuy√™n gia gi√°o d·ª•c. H√£y t·∫°o m·ªôt d√†n √Ω b√†i gi·∫£ng th·∫≠t chi ti·∫øt d·ª±a v√†o y√™u c·∫ßu c·ªßa user.
            
            Tr·∫£ v·ªÅ JSON v·ªõi format sau:
            {
                "title": "ti√™u ƒë·ªÅ b√†i gi·∫£ng",
                "subject": "m√¥n h·ªçc", 
                "grade": "c·∫•p ƒë·ªô h·ªçc (elementary/middle/high/university)",
                "duration": "th·ªùi l∆∞·ª£ng (ph√∫t)",
                "objectives": ["m·ª•c ti√™u 1", "m·ª•c ti√™u 2", "..."],
                "outline": [
                    {
                        "section": "Ph·∫ßn I: T√™n ph·∫ßn",
                        "duration": "15 ph√∫t",
                        "topics": [
                            {
                                "main_topic": "ƒê·∫ßu m·ª•c l·ªõn 1",
                                "subtopics": [
                                    {
                                        "subtitle": "ƒê·∫ßu m·ª•c nh·ªè 1.1",
                                        "content": "N·ªôi dung chi ti·∫øt...",
                                        "activities": ["ho·∫°t ƒë·ªông 1", "ho·∫°t ƒë·ªông 2"]
                                    }
                                ]
                            }
                        ]
                    }
                ],
                "resources": ["t√†i li·ªáu 1", "t√†i li·ªáu 2"],
                "assessment": "ph∆∞∆°ng ph√°p ƒë√°nh gi√°"
            }
            
            H√£y t·∫°o d√†n √Ω th·∫≠t chi ti·∫øt v√† ph√π h·ª£p v·ªõi y√™u c·∫ßu.
            """
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Y√™u c·∫ßu: {state.message}")
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Parse and create lecture (simplified)
            import json
            import re
            try:
                # Try to extract JSON from response
                response_text = response.content
                logger.info(f"Raw response: {response_text}")
                
                                # Try direct JSON parsing first
                try:
                    lecture_data = json.loads(response_text)
                    logger.info(f"lecture_data: {lecture_data}")
                except json.JSONDecodeError:
                    # If direct parsing fails, try to extract JSON block
                    json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                    if json_match:
                        json_str = json_match.group(0)
                        lecture_data = json.loads(json_str)
                    else:
                        # Fallback: create simple data from response text
                        lecture_data = {
                            "title": "B√†i gi·∫£ng theo y√™u c·∫ßu",
                            "subject": "T·ªïng h·ª£p",
                            "grade": "elementary",
                            "duration": "45 ph√∫t",
                            "objectives": ["Hi·ªÉu n·ªôi dung c∆° b·∫£n"],
                            "outline": [{
                                "section": "Ph·∫ßn ch√≠nh",
                                "duration": "30 ph√∫t",
                                "topics": [{
                                    "main_topic": "N·ªôi dung ch√≠nh",
                                    "subtopics": [{
                                        "subtitle": "Chi ti·∫øt",
                                        "content": response_text[:200] + "...",
                                        "activities": ["Th·∫£o lu·∫≠n", "Th·ª±c h√†nh"]
                                    }]
                                }]
                            }],
                            "resources": ["T√†i li·ªáu tham kh·∫£o"],
                            "assessment": "ƒê√°nh gi√° qua b√†i t·∫≠p"
                        }

                # Prepare response with detailed lecture outline
                state.response = f"‚úÖ **D√†n √Ω b√†i gi·∫£ng: {lecture_data.get('title')}**\n\n"
                
                # Set metadata for FE to recognize this as a lecture response
                state.metadata = {
                    "type": "lecture",
                    "lecture_data": lecture_data,
                    "editable": True,
                    "show_create_slide_button": True
                }
                state.tools_used.append("create_lecture")
                        
            except json.JSONDecodeError as e:
                logger.error(f"Error parsing JSON response: {e}")
                state.response = "Kh√¥ng th·ªÉ hi·ªÉu y√™u c·∫ßu t·∫°o b√†i gi·∫£ng. Vui l√≤ng m√¥ t·∫£ chi ti·∫øt h∆°n."
            except httpx.ReadTimeout as e:
                logger.error(f"Timeout khi g·ªçi backend: {e}")
                state.response = "Backend ph·∫£n h·ªìi ch·∫≠m. Vui l√≤ng th·ª≠ l·∫°i sau."
            except Exception as e:
                logger.error(f"Error creating lecture: {e}")
                state.response = f"C√≥ l·ªói x·∫£y ra khi t·∫°o b√†i gi·∫£ng: {str(e)}"
            
            return state
            
        except Exception as e:
            logger.error(f"Error in handle_lecture_creation: {e}")
            state.response = "C√≥ l·ªói x·∫£y ra khi t·∫°o b√†i gi·∫£ng."
            return state
    
    async def handle_slide_creation(self, state: AgentState) -> AgentState:
        """X·ª≠ l√Ω t·∫°o slide"""
        try:
            # Similar to lecture creation but for slides
            system_prompt = """
            H√£y tr√≠ch xu·∫•t th√¥ng tin ƒë·ªÉ t·∫°o slide t·ª´ y√™u c·∫ßu c·ªßa user.
            
            Tr·∫£ v·ªÅ JSON v·ªõi format:
            {
                "title": "ti√™u ƒë·ªÅ slide",
                "subject": "m√¥n h·ªçc",
                "presentation_type": "lecture/workshop/seminar/conference",
                "duration": 45,
                "requirements": "y√™u c·∫ßu chi ti·∫øt v·ªÅ n·ªôi dung slide"
            }
            """
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Y√™u c·∫ßu: {state.message}")
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Parse and create slide
            import json
            import re
            try:
                # Try to extract JSON from response
                response_text = response.content
                logger.info(f"Raw slide response: {response_text}")
                
                # Try direct JSON parsing first
                try:
                    slide_data = json.loads(response_text)
                except json.JSONDecodeError:
                    # If direct parsing fails, try to extract JSON block
                    json_match = re.search(r'\{[^}]*\}', response_text, re.DOTALL)
                    if json_match:
                        json_str = json_match.group(0)
                        slide_data = json.loads(json_str)
                    else:
                        # Fallback: create data from response text
                        slide_data = {
                            "title": "Slide theo y√™u c·∫ßu",
                            "type": "content",
                            "content": state.message
                        }
                
                # Call backend to create slide
                async with httpx.AsyncClient() as client:
                    backend_response = await client.post(
                        f"{self.backend_url}/tools/create-slide-draft",
                        json={
                            "title": slide_data.get("title", "Slide m·ªõi"),
                            "subject": slide_data.get("subject", ""),
                            "presentation_type": slide_data.get("presentation_type"),
                            "duration": slide_data.get("duration"),
                            "requirements": slide_data.get("requirements", state.message),
                            "user_id": state.user_id
                        }
                    )
                    
                    if backend_response.status_code == 200:
                        result = backend_response.json()
                        state.response = f"T√¥i ƒë√£ t·∫°o slide '{slide_data.get('title')}' cho b·∫°n. Slide ƒëang ƒë∆∞·ª£c sinh n·ªôi dung t·ª± ƒë·ªông v√† s·∫Ω s·∫µn s√†ng trong v√†i ph√∫t."
                        state.metadata["slide_id"] = result.get("slide_id")
                        state.tools_used.append("create_slide")
                    else:
                        state.response = "C√≥ l·ªói x·∫£y ra khi t·∫°o slide. Vui l√≤ng th·ª≠ l·∫°i."
                        
            except Exception as e:
                logger.error(f"Error parsing slide data: {e}")
                state.response = "Kh√¥ng th·ªÉ hi·ªÉu y√™u c·∫ßu t·∫°o slide. Vui l√≤ng m√¥ t·∫£ chi ti·∫øt h∆°n."
            
            return state
            
        except Exception as e:
            logger.error(f"Error in handle_slide_creation: {e}")
            state.response = "C√≥ l·ªói x·∫£y ra khi t·∫°o slide."
            return state
    
    async def handle_search(self, state: AgentState) -> AgentState:
        """X·ª≠ l√Ω t√¨m ki·∫øm"""
        try:
            # Search both lectures and slides
            async with httpx.AsyncClient() as client:
                # Search lectures
                lecture_response = await client.post(
                    f"{self.backend_url}/tools/search-lectures",
                    json={
                        "query": state.message,
                        "user_id": state.user_id,
                        "limit": 3
                    }
                )
                
                # Search slides
                slide_response = await client.post(
                    f"{self.backend_url}/tools/search-slides",
                    json={
                        "query": state.message,
                        "user_id": state.user_id,
                        "limit": 3
                    }
                )
                
                lectures = []
                slides = []
                
                if lecture_response.status_code == 200:
                    lecture_data = lecture_response.json()
                    lectures = lecture_data.get("lectures", [])
                
                if slide_response.status_code == 200:
                    slide_data = slide_response.json()
                    slides = slide_data.get("slides", [])
                
                # Format response
                if lectures or slides:
                    response_parts = ["T√¥i t√¨m th·∫•y c√°c t√†i li·ªáu sau:\n"]
                    
                    if lectures:
                        response_parts.append("üìö **B√†i gi·∫£ng:**")
                        for lecture in lectures:
                            response_parts.append(f"- {lecture['title']} ({lecture['subject']})")
                    
                    if slides:
                        response_parts.append("\nüéØ **Slides:**")
                        for slide in slides:
                            response_parts.append(f"- {slide['title']} ({slide['slide_count']} slides)")
                    
                    state.response = "\n".join(response_parts)
                    state.metadata["search_results"] = {"lectures": lectures, "slides": slides}
                    state.tools_used.append("search")
                else:
                    state.response = "Kh√¥ng t√¨m th·∫•y t√†i li·ªáu n√†o ph√π h·ª£p. B·∫°n c√≥ mu·ªën t√¥i t·∫°o m·ªõi kh√¥ng?"
            
            return state
            
        except Exception as e:
            logger.error(f"Error in handle_search: {e}")
            state.response = "C√≥ l·ªói x·∫£y ra khi t√¨m ki·∫øm."
            return state
    
    async def generate_response(self, state: AgentState) -> AgentState:
        """T·∫°o ph·∫£n h·ªìi cu·ªëi c√πng"""
        # Response ƒë√£ ƒë∆∞·ª£c t·∫°o ·ªü c√°c handler tr∆∞·ªõc ƒë√≥
        if not state.response:
            state.response = "T√¥i ch∆∞a hi·ªÉu y√™u c·∫ßu c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ m√¥ t·∫£ chi ti·∫øt h∆°n kh√¥ng?"
        
        return state
    
    async def process(self, request: ProcessRequest) -> ProcessResponse:
        """X·ª≠ l√Ω request ch√≠nh"""
        try:
            # Create initial state
            initial_state = AgentState(
                message=request.message,
                chat_history=request.chat_history,
                user_id=request.user_id
            ).model_dump()
            
            # Run the graph
            config = {"configurable": {"thread_id": request.user_id or "default"}}
            result = await self.graph.ainvoke(initial_state, config)
            
            return ProcessResponse(
                reply=result.get("response", "Xin l·ªói, kh√¥ng th·ªÉ t·∫°o ph·∫£n h·ªìi."),
                metadata=result.get("metadata", {})
            )
            
        except Exception as e:
            logger.error(f"Error processing request: {e}")
            return ProcessResponse(
                reply="Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau.",
                metadata={"error": True}
            )

# Initialize agent
agent = EduBotAgent()

# API Endpoints
@app.post("/process", response_model=ProcessResponse)
async def process_message(request: ProcessRequest):
    """Main endpoint ƒë·ªÉ x·ª≠ l√Ω tin nh·∫Øn"""
    return await agent.process(request)

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "main_agent"}

@app.post("/generate/lecture")
async def generate_lecture(request: LectureGenerationRequest):
    """Generate lecture content"""
    try:
        system_prompt = f"""
        B·∫°n l√† chuy√™n gia gi√°o d·ª•c. H√£y t·∫°o m·ªôt b√†i gi·∫£ng chi ti·∫øt v·ªõi c√°c y√™u c·∫ßu sau:
        
        Ti√™u ƒë·ªÅ: {request.title}
        M√¥n h·ªçc: {request.subject}
        C·∫•p ƒë·ªô: {request.grade or "Kh√¥ng x√°c ƒë·ªãnh"}
        Y√™u c·∫ßu: {request.requirements}
        
        B√†i gi·∫£ng c·∫ßn c√≥:
        1. M·ª•c ti√™u h·ªçc t·∫≠p r√µ r√†ng
        2. N·ªôi dung chi ti·∫øt theo t·ª´ng ph·∫ßn
        3. Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y ph√π h·ª£p
        4. B√†i t·∫≠p v√† c√¢u h·ªèi ki·ªÉm tra
        5. T√†i li·ªáu tham kh·∫£o
        
        H√£y vi·∫øt b√†i gi·∫£ng ƒë·∫ßy ƒë·ªß v√† chuy√™n nghi·ªáp.
        """
        
        messages = [SystemMessage(content=system_prompt)]
        response = await llm.ainvoke(messages)
        
        return {
            "content": response.content,
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"Error generating lecture: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate/slide")
async def generate_slide(request: SlideGenerationRequest):
    """Generate slide content"""
    try:
        system_prompt = f"""
        B·∫°n l√† chuy√™n gia thi·∫øt k·∫ø slide gi√°o d·ª•c. H√£y t·∫°o n·ªôi dung slide v·ªõi c√°c y√™u c·∫ßu sau:
        
        Ti√™u ƒë·ªÅ: {request.title}
        M√¥n h·ªçc: {request.subject}
        Lo·∫°i thuy·∫øt tr√¨nh: {request.presentation_type or "B√†i gi·∫£ng"}
        Th·ªùi l∆∞·ª£ng: {request.duration or 45} ph√∫t
        Y√™u c·∫ßu: {request.requirements}
        
        T·∫°o t·ª´ 10-15 slides bao g·ªìm:
        1. Slide ti√™u ƒë·ªÅ
        2. Slide m·ª•c ti√™u
        3. Slide n·ªôi dung ch√≠nh (8-10 slides)
        4. Slide t·ªïng k·∫øt
        5. Slide Q&A
        
        M·ªói slide tr·∫£ v·ªÅ JSON format:
        {{
            "title": "Ti√™u ƒë·ªÅ slide",
            "content": "N·ªôi dung slide",
            "slide_type": "title/content/image/conclusion",
            "notes": "Ghi ch√∫ cho gi√°o vi√™n"
        }}
        
        Tr·∫£ v·ªÅ array c√°c slides theo format tr√™n.
        """
        
        messages = [SystemMessage(content=system_prompt)]
        response = await llm.ainvoke(messages)
        
        # Parse slides (simplified - would need better parsing)
        try:
            import json
            import re
            response_text = response.content
            logger.info(f"Raw slides response: {response_text}")
            
            try:
                slides = json.loads(response_text)
            except json.JSONDecodeError:
                # Try to extract JSON array
                json_match = re.search(r'\[[^\]]*\]', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    slides = json.loads(json_str)
                else:
                    raise ValueError("No JSON found")
        except:
            # Fallback if parsing fails
            slides = [
                {
                    "title": request.title,
                    "content": response.content,
                    "slide_type": "content",
                    "notes": "N·ªôi dung ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông"
                }
            ]
        
        return {
            "slides": slides,
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"Error generating slide: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate/slide-from-lecture")
async def generate_slide_from_lecture(request: SlideFromLectureRequest):
    """Generate slides from lecture content"""
    try:
        system_prompt = f"""
        H√£y t·∫°o slide thuy·∫øt tr√¨nh t·ª´ n·ªôi dung b√†i gi·∫£ng sau:
        
        Ti√™u ƒë·ªÅ b√†i gi·∫£ng: {request.lecture_title}
        M√¥n h·ªçc: {request.lecture_subject}
        N·ªôi dung: {request.lecture_content[:2000]}...
        
        T√πy ch·ªçn:
        - Slide gi·ªõi thi·ªáu: {request.include_intro}
        - Slide k·∫øt lu·∫≠n: {request.include_conclusion}
        - Slide c√¢u h·ªèi: {request.include_questions}
        - Phong c√°ch: {request.slide_style}
        
        T·∫°o 8-12 slides v·ªõi format JSON nh∆∞ sau:
        [
            {{
                "title": "Ti√™u ƒë·ªÅ slide",
                "content": "N·ªôi dung slide",
                "slide_type": "title/content/conclusion/question",
                "notes": "Ghi ch√∫"
            }}
        ]
        """
        
        messages = [SystemMessage(content=system_prompt)]
        response = await llm.ainvoke(messages)
        
        # Parse slides
        try:
            import json
            import re
            response_text = response.content
            logger.info(f"Raw lecture slides response: {response_text}")
            
            try:
                slides = json.loads(response_text)
            except json.JSONDecodeError:
                # Try to extract JSON array
                json_match = re.search(r'\[[^\]]*\]', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    slides = json.loads(json_str)
                else:
                    raise ValueError("No JSON found")
        except:
            slides = [
                {
                    "title": f"Slide: {request.lecture_title}",
                    "content": response.content,
                    "slide_type": "content",
                    "notes": "ƒê∆∞·ª£c t·∫°o t·ª´ b√†i gi·∫£ng"
                }
            ]
        
        return {
            "slides": slides,
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"Error generating slide from lecture: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
